groups:
  - name: chatbot.rules
    rules:
    # High-level service availability
    - alert: ChatbotBackendDown
      expr: up{job="chatbot-backend"} == 0
      for: 1m
      labels:
        severity: critical
        service: chatbot-backend
      annotations:
        summary: "Chatbot backend is down"
        description: "Chatbot backend has been down for more than 1 minute."
        runbook_url: "https://runbooks.yourdomain.com/chatbot-backend-down"

    - alert: ChatbotFrontendDown
      expr: up{job="chatbot-frontend"} == 0
      for: 1m
      labels:
        severity: critical
        service: chatbot-frontend
      annotations:
        summary: "Chatbot frontend is down"
        description: "Chatbot frontend has been down for more than 1 minute."

    # Database alerts
    - alert: PostgreSQLDown
      expr: up{job="postgres"} == 0
      for: 30s
      labels:
        severity: critical
        service: postgres
      annotations:
        summary: "PostgreSQL is down"
        description: "PostgreSQL database has been down for more than 30 seconds."

    - alert: PostgreSQLTooManyConnections
      expr: sum(pg_stat_activity_count) by (instance) > 180
      for: 2m
      labels:
        severity: warning
        service: postgres
      annotations:
        summary: "PostgreSQL has too many connections"
        description: "PostgreSQL instance {{ $labels.instance }} has {{ $value }} connections (> 180)."

    - alert: PostgreSQLHighConnectionUtilization
      expr: (sum(pg_stat_activity_count) by (instance) / sum(pg_settings_max_connections) by (instance)) * 100 > 80
      for: 5m
      labels:
        severity: warning
        service: postgres
      annotations:
        summary: "PostgreSQL connection utilization is high"
        description: "PostgreSQL connection utilization is {{ $value }}% on {{ $labels.instance }}."

    # Redis alerts
    - alert: RedisDown
      expr: up{job="redis"} == 0
      for: 30s
      labels:
        severity: critical
        service: redis
      annotations:
        summary: "Redis is down"
        description: "Redis has been down for more than 30 seconds."

    - alert: RedisHighMemoryUsage
      expr: (redis_memory_used_bytes / redis_memory_max_bytes) * 100 > 90
      for: 5m
      labels:
        severity: warning
        service: redis
      annotations:
        summary: "Redis memory usage is high"
        description: "Redis memory usage is {{ $value }}% on {{ $labels.instance }}."

    # Application performance alerts
    - alert: HighResponseTime
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="chatbot-backend"}[5m])) > 2
      for: 5m
      labels:
        severity: warning
        service: chatbot-backend
      annotations:
        summary: "High response time detected"
        description: "95th percentile response time is {{ $value }}s for {{ $labels.instance }}."

    - alert: HighErrorRate
      expr: rate(http_requests_total{job="chatbot-backend",status=~"5.."}[5m]) / rate(http_requests_total{job="chatbot-backend"}[5m]) > 0.05
      for: 5m
      labels:
        severity: critical
        service: chatbot-backend
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.instance }}."

    - alert: LowRequestRate
      expr: rate(http_requests_total{job="chatbot-backend"}[5m]) < 0.1
      for: 10m
      labels:
        severity: warning
        service: chatbot-backend
      annotations:
        summary: "Low request rate detected"
        description: "Request rate is {{ $value }} requests/second for {{ $labels.instance }}."

    # Resource utilization alerts
    - alert: HighCPUUsage
      expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
      for: 5m
      labels:
        severity: warning
        service: system
      annotations:
        summary: "High CPU usage detected"
        description: "CPU usage is {{ $value }}% on {{ $labels.instance }}."

    - alert: HighMemoryUsage
      expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
      for: 5m
      labels:
        severity: warning
        service: system
      annotations:
        summary: "High memory usage detected"
        description: "Memory usage is {{ $value }}% on {{ $labels.instance }}."

    - alert: HighDiskUsage
      expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 85
      for: 5m
      labels:
        severity: warning
        service: system
      annotations:
        summary: "High disk usage detected"
        description: "Disk usage is {{ $value }}% on {{ $labels.instance }} for {{ $labels.mountpoint }}."

    # Kubernetes alerts
    - alert: KubernetesPodCrashLooping
      expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
      for: 5m
      labels:
        severity: warning
        service: kubernetes
      annotations:
        summary: "Pod is crash looping"
        description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping."

    - alert: KubernetesPodNotReady
      expr: kube_pod_status_ready{condition="false"} == 1
      for: 5m
      labels:
        severity: warning
        service: kubernetes
      annotations:
        summary: "Pod is not ready"
        description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been not ready for more than 5 minutes."

    - alert: KubernetesDeploymentReplicasMismatch
      expr: kube_deployment_spec_replicas != kube_deployment_status_available_replicas
      for: 5m
      labels:
        severity: warning
        service: kubernetes
      annotations:
        summary: "Deployment replicas mismatch"
        description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has {{ $labels.spec_replicas }} desired but {{ $labels.available_replicas }} available replicas."

    # Business logic alerts
    - alert: HighDocumentProcessingFailureRate
      expr: rate(document_processing_failures_total[5m]) / rate(document_processing_total[5m]) > 0.1
      for: 5m
      labels:
        severity: warning
        service: chatbot-backend
      annotations:
        summary: "High document processing failure rate"
        description: "Document processing failure rate is {{ $value | humanizePercentage }}."

    - alert: ChatSessionsStuck
      expr: increase(chat_sessions_created_total[1h]) - increase(chat_sessions_ended_total[1h]) > 100
      for: 10m
      labels:
        severity: warning
        service: chatbot-backend
      annotations:
        summary: "Many chat sessions appear to be stuck"
        description: "{{ $value }} more sessions were created than ended in the last hour."

    - alert: HighRAGQueryLatency
      expr: histogram_quantile(0.95, rate(rag_query_duration_seconds_bucket[5m])) > 5
      for: 5m
      labels:
        severity: warning
        service: chatbot-backend
      annotations:
        summary: "High RAG query latency"
        description: "95th percentile RAG query latency is {{ $value }}s."

    # Security alerts
    - alert: HighFailedLoginAttempts
      expr: rate(failed_login_attempts_total[5m]) > 10
      for: 2m
      labels:
        severity: warning
        service: security
      annotations:
        summary: "High number of failed login attempts"
        description: "{{ $value }} failed login attempts per second detected."

    - alert: SuspiciousIPActivity
      expr: rate(security_events_total{event_type="suspicious_ip"}[5m]) > 1
      for: 1m
      labels:
        severity: critical
        service: security
      annotations:
        summary: "Suspicious IP activity detected"
        description: "{{ $value }} suspicious IP events per second detected."

  - name: infrastructure.rules
    rules:
    # Certificate expiration
    - alert: SSLCertificateExpiringSoon
      expr: probe_ssl_earliest_cert_expiry - time() < 86400 * 7
      for: 1h
      labels:
        severity: warning
        service: ssl
      annotations:
        summary: "SSL certificate expiring soon"
        description: "SSL certificate for {{ $labels.instance }} expires in {{ $value | humanizeDuration }}."

    # External service monitoring
    - alert: ExternalServiceDown
      expr: probe_success{job="blackbox"} == 0
      for: 2m
      labels:
        severity: critical
        service: external
      annotations:
        summary: "External service is down"
        description: "External service {{ $labels.instance }} has been down for more than 2 minutes."

    # Backup alerts
    - alert: DatabaseBackupFailed
      expr: time() - database_backup_last_success_timestamp > 86400
      for: 1h
      labels:
        severity: critical
        service: backup
      annotations:
        summary: "Database backup failed"
        description: "Database backup has not succeeded for more than 24 hours."
